import pandas as pd
import pandas_profiling as pdp
import multiprocessing
from tqdm import tqdm
import setting
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, roc_curve, auc, accuracy_score
import xgboost as xgb
import matplotlib.pyplot as plt

dtypes = setting.DTYPES
ID = 'MachineIdentifier'
TARGET = 'HasDetections'


def load_dataframe(dataset):
    usecols = dtypes.keys()
    if dataset == 'test':
        usecols = [col for col in dtypes.keys() if col != 'HasDetections']
    df = pd.read_csv(f'data/{dataset}.csv', dtype=dtypes, usecols=usecols, header=0)
    return df


if __name__ == '__main__':
    with multiprocessing.Pool() as pool:
        df_train, df_test = pool.map(load_dataframe, ["train", "test"])
    # df_train = load_dataframe('train')

    # print(df_train.info())
    feature_columns = [x for x in df_train.columns if x not in [TARGET, ID]]

    # y_train = pd.get_dummies(y_train)

    df_train.fillna(df_train.median(), inplace=True)
    # x_train.replace('<', '', inplace=True)
    le = LabelEncoder()

    x_dtypes = df_train[feature_columns].dtypes
    for column in x_dtypes[x_dtypes == 'object'].index:
        le = LabelEncoder()
        df_train[column] = le.fit_transform(df_train[column].astype(str))

    df_train[feature_columns] = MinMaxScaler().fit_transform(df_train[feature_columns])

    x_train, x_valid, y_train, y_valid = train_test_split(df_train[feature_columns], df_train[TARGET], test_size=0.2,
                                                          random_state=0)

    print('x train shape:', x_train.shape)
    print('x valid shape:', x_valid.shape)
    print('y train shape:', y_train.shape)
    print('y valid shape:', y_valid.shape)

    xgb_clf = xgb.XGBClassifier(n_estimators=100,
                                learning_rate=0.1,
                                max_depth=5,
                                min_child_weight=1,
                                gamma=0,
                                subsample=0.8,
                                colsample_bytree=0.8,
                                scale_pos_weight=1,
                                objective='binary:logistic',
                                nthread=8,
                                silent=False)
    # clf = RandomForestClassifier(n_jobs=-1, verbose=3)
    xgb_param = xgb_clf.get_xgb_params()
    xgtrain = xgb.DMatrix(x_train.values, label=y_train.values)
    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=xgb_clf.get_params()['n_estimators'], nfold=5,
                      metrics='auc', early_stopping_rounds=50)
    xgb_clf.set_params(n_estimators=cvresult.shape[0])
    xgb_clf.fit(x_train, y_train, eval_metric='auc')

    y_pred = xgb_clf.predict(x_valid)
    y_pred = pd.Series(y_pred)

    fpr, tpr, thresholds = roc_curve(y_valid, y_pred, pos_label=1)

    print(accuracy_score(y_valid, y_pred))
    print(classification_report(y_valid, y_pred))
    print(auc(fpr, tpr))

    y_pred_proba = xgb_clf.predict_proba(x_valid)
    df_proba = pd.DataFrame(y_pred_proba)
    print(y_pred_proba)
